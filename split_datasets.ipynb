{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, load_from_disk, concatenate_datasets, disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder where the dataset was saved\n",
    "cache_dir = \"./datasets\"\n",
    "\n",
    "# Load the dataset from the saved folder\n",
    "dataset = load_dataset(\"b-mc2/sql-create-context\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 78577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT COUNT(*) FROM head WHERE age > 56',\n",
       " 'question': 'How many heads of the departments are older than 56 ?',\n",
       " 'context': 'CREATE TABLE head (age INTEGER)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset['train'].take(2000)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testval_split = train_data.train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "# Further split the test+val set into validation and test (e.g., 50% of 20% = 10% each)\n",
    "test_val_split = train_testval_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Combine splits into a DatasetDict\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_testval_split[\"train\"],\n",
    "    \"val\": test_val_split[\"train\"],\n",
    "    \"test\": test_val_split[\"test\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./datasets/sql-create-context-split\"\n",
    "# split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset = load_from_disk(\"./datasets/sql-create-context-split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    eval: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = load_dataset(\"json\", data_files={'eval':\"./datasets/sql_eval_dataset.json\"})\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train_test = eval_dataset[\"eval\"].train_test_split(test_size=0.4, seed=42)\n",
    "eval_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    train_append: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train_test[\"train_append\"] = eval_train_test[\"train\"].select_columns(['answer', 'question', 'context'])\n",
    "eval_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"train\"] = concatenate_datasets([split_dataset[\"train\"].take(750)] + [eval_train_test[\"train_append\"]]*5)\n",
    "split_dataset[\"train\"] = split_dataset[\"train\"].shuffle(seed=42)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    eval_train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    eval_test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"eval_train\"] = eval_train_test[\"train\"]\n",
    "split_dataset[\"eval_test\"] = eval_train_test[\"test\"]\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e826e2198147e7a86d6d184b84c317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df95ea4b244456c916c3e1dc9524594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453c6deb36c64b8192b9834568e2d4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5888f8db476437faae67b0275be92b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6ce033b13048df86a51be705ed8a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = \"./datasets/train_merge_150x5_750\"\n",
    "split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \"SELECT name FROM restaurant WHERE food_type ILIKE '%Italian%' OR city_name ILIKE '%New York%' ORDER BY name NULLS LAST;\",\n",
       " 'question': 'Which restaurants serve Italian cuisine or are located in New York? Order the results by the restaurant name.',\n",
       " 'context': 'CREATE TABLE public.geographic (city_name text, county text, region text);\\n\\nCREATE TABLE public.location (restaurant_id bigint, house_number bigint, street_name text, city_name text);\\n\\nCREATE TABLE public.restaurant (id bigint, name text, food_type text, city_name text, rating real);'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"train\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
