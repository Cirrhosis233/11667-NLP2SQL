{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder where the dataset was saved\n",
    "cache_dir = \"./datasets\"\n",
    "\n",
    "# Load the dataset from the saved folder\n",
    "dataset = load_dataset(\"b-mc2/sql-create-context\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 78577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT COUNT(*) FROM head WHERE age > 56',\n",
       " 'question': 'How many heads of the departments are older than 56 ?',\n",
       " 'context': 'CREATE TABLE head (age INTEGER)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset['train'].take(2000)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testval_split = train_data.train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "# Further split the test+val set into validation and test (e.g., 50% of 20% = 10% each)\n",
    "test_val_split = train_testval_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Combine splits into a DatasetDict\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_testval_split[\"train\"],\n",
    "    \"val\": test_val_split[\"train\"],\n",
    "    \"test\": test_val_split[\"test\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./datasets/sql-create-context-split\"\n",
    "# split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset = load_from_disk(\"./datasets/sql-create-context-split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    eval: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = load_dataset(\"json\", data_files={'eval':\"./datasets/sql_eval_dataset.json\"})\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"eval\"] = eval_dataset[\"eval\"]\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which authors have written publications in both the domain \"Machine Learning\" and the domain \"Data Science\"?',\n",
       " 'answer': \"SELECT {author.name,author.aid} FROM author WHERE author.aid IN (SELECT domain_author.aid FROM domain_author WHERE domain_author.did IN (SELECT domain.did FROM DOMAIN WHERE domain.name IN ('Machine Learning', 'Data Science') ) GROUP BY 1 HAVING COUNT(DISTINCT domain_author.did) = 2);\",\n",
       " 'db_name': 'academic',\n",
       " 'context': 'CREATE TABLE public.author (aid BIGINT NOT NULL, homepage TEXT, name TEXT, oid BIGINT);\\nCREATE TABLE public.cite (cited BIGINT, citing BIGINT);\\nCREATE TABLE public.conference (cid BIGINT NOT NULL, homepage TEXT, name TEXT);\\nCREATE TABLE public.domain (did BIGINT NOT NULL, name TEXT);\\nCREATE TABLE public.domain_author (aid BIGINT NOT NULL, did BIGINT NOT NULL);\\nCREATE TABLE public.domain_conference (cid BIGINT NOT NULL, did BIGINT NOT NULL);\\nCREATE TABLE public.domain_journal (did BIGINT NOT NULL, jid BIGINT NOT NULL);\\nCREATE TABLE public.domain_keyword (did BIGINT NOT NULL, kid BIGINT NOT NULL);\\nCREATE TABLE public.domain_publication (did BIGINT NOT NULL, pid BIGINT NOT NULL);\\nCREATE TABLE public.journal (homepage TEXT, jid BIGINT NOT NULL, name TEXT);\\nCREATE TABLE public.keyword (keyword TEXT, kid BIGINT NOT NULL);\\nCREATE TABLE public.organization (continent TEXT, homepage TEXT, name TEXT, oid BIGINT NOT NULL);\\nCREATE TABLE public.publication (abstract TEXT, cid BIGINT, citation_num BIGINT, jid BIGINT, pid BIGINT NOT NULL, reference_num BIGINT, title TEXT, year BIGINT);\\nCREATE TABLE public.publication_keyword (pid BIGINT NOT NULL, kid BIGINT NOT NULL);\\nCREATE TABLE public.writes (aid BIGINT NOT NULL, pid BIGINT NOT NULL);',\n",
       " 'query_category': 'group_by'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"eval\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea68835a27c4b8cbe32aa7bc1492a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d9d5314def4655a7946f529edfe2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f127cc4e2a2d4dd092d4e63e32ebaf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71bdb1d08264480bd8d56ae0f771e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = \"./datasets/sql-create-context-split\"\n",
    "split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
