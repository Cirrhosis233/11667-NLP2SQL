{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, load_from_disk, concatenate_datasets, disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder where the dataset was saved\n",
    "cache_dir = \"./datasets\"\n",
    "\n",
    "# Load the dataset from the saved folder\n",
    "dataset = load_dataset(\"b-mc2/sql-create-context\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 78577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT COUNT(*) FROM head WHERE age > 56',\n",
       " 'question': 'How many heads of the departments are older than 56 ?',\n",
       " 'context': 'CREATE TABLE head (age INTEGER)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset['train'].take(2000)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testval_split = train_data.train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "# Further split the test+val set into validation and test (e.g., 50% of 20% = 10% each)\n",
    "test_val_split = train_testval_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Combine splits into a DatasetDict\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_testval_split[\"train\"],\n",
    "    \"val\": test_val_split[\"train\"],\n",
    "    \"test\": test_val_split[\"test\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./datasets/sql-create-context-split\"\n",
    "# split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset = load_from_disk(\"./datasets/sql-create-context-split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    eval: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = load_dataset(\"json\", data_files={'eval':\"./datasets/sql_eval_dataset_executable_gold.json\"})\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train_test = eval_dataset[\"eval\"].train_test_split(test_size=0.4, seed=42)\n",
    "eval_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    train_append: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train_test[\"train_append\"] = eval_train_test[\"train\"].select_columns(['answer', 'question', 'context'])\n",
    "eval_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_for_training(dataset, prompt_file):\n",
    "    with open(prompt_file, \"r\") as f:\n",
    "        prompt = f.read()\n",
    "    columns = dataset.features.keys()\n",
    "\n",
    "    def preprocess_function(sample):\n",
    "        sample[\"text\"] = prompt.format(\n",
    "            user_question=sample[\"question\"],\n",
    "            table_metadata_string=sample[\"context\"],\n",
    "            sql=(\n",
    "                sample[\"answer\"]\n",
    "                if sample[\"answer\"].endswith(\";\")\n",
    "                else sample[\"answer\"] + \";\"\n",
    "            ),\n",
    "        ).strip()\n",
    "\n",
    "        return sample\n",
    "\n",
    "    train_dataset = dataset.map(\n",
    "        preprocess_function,\n",
    "        remove_columns=columns,\n",
    "    )\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc501d66ff94876a1438598819780fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 150\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train = prepare_dataset_for_training(eval_train_test[\"train_append\"], prompt_file=\"./prompts/prompt_v4_postgres_train.md\")\n",
    "eval_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Task\\nGenerate a SQL query to answer [QUESTION]What is the total number of credits earned by students in each program?[/QUESTION]\\n\\n### Instructions\\n- Use PostgreSQL Syntax\\n- End the SQL query with \";\"\\n\\n### Database Schema\\nThe query will run on a database with the following schema:\\nCREATE TABLE public.area (course_id BIGINT, area TEXT);\\nCREATE TABLE public.comment_instructor (instructor_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, student_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, score BIGINT, comment_text TEXT);\\nCREATE TABLE public.course (course_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, name TEXT, department TEXT, number TEXT, credits TEXT, advisory_requirement TEXT, enforced_requirement TEXT, description TEXT, num_semesters BIGINT, num_enrolled BIGINT, has_discussion BOOLEAN, has_lab BOOLEAN, has_projects BOOLEAN, has_exams BOOLEAN, num_reviews BIGINT, clarity_score BIGINT, easiness_score BIGINT, helpfulness_score BIGINT);\\nCREATE TABLE public.course_offering (offering_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, course_id BIGINT, semester BIGINT, section_number BIGINT, start_time TIME, end_time TIME, monday TEXT, tuesday TEXT, wednesday TEXT, thursday TEXT, friday TEXT, saturday TEXT, sunday TEXT, has_final_project BOOLEAN, has_final_exam BOOLEAN, textbook TEXT, class_address TEXT, allow_audit TEXT DEFAULT \\'false\\'::TEXT);\\nCREATE TABLE public.course_prerequisite (pre_course_id BIGINT NOT NULL, course_id BIGINT NOT NULL);\\nCREATE TABLE public.course_tags_count (course_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, clear_grading BIGINT DEFAULT \\'0\\'::BIGINT, pop_quiz BIGINT DEFAULT \\'0\\'::BIGINT, group_projects BIGINT DEFAULT \\'0\\'::BIGINT, inspirational BIGINT DEFAULT \\'0\\'::BIGINT, long_lectures BIGINT DEFAULT \\'0\\'::BIGINT, extra_credit BIGINT DEFAULT \\'0\\'::BIGINT, few_tests BIGINT DEFAULT \\'0\\'::BIGINT, good_feedback BIGINT DEFAULT \\'0\\'::BIGINT, tough_tests BIGINT DEFAULT \\'0\\'::BIGINT, heavy_papers BIGINT DEFAULT \\'0\\'::BIGINT, cares_for_students BIGINT DEFAULT \\'0\\'::BIGINT, heavy_assignments BIGINT DEFAULT \\'0\\'::BIGINT, respected BIGINT DEFAULT \\'0\\'::BIGINT, participation BIGINT DEFAULT \\'0\\'::BIGINT, heavy_reading BIGINT DEFAULT \\'0\\'::BIGINT, tough_grader BIGINT DEFAULT \\'0\\'::BIGINT, hilarious BIGINT DEFAULT \\'0\\'::BIGINT, would_take_again BIGINT DEFAULT \\'0\\'::BIGINT, good_lecture BIGINT DEFAULT \\'0\\'::BIGINT, no_skip BIGINT DEFAULT \\'0\\'::BIGINT);\\nCREATE TABLE public.instructor (instructor_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, name TEXT, uniqname TEXT);\\nCREATE TABLE public.offering_instructor (offering_instructor_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, offering_id BIGINT, instructor_id BIGINT);\\nCREATE TABLE public.program (program_id BIGINT NOT NULL, name TEXT, college TEXT, introduction TEXT);\\nCREATE TABLE public.program_course (program_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, course_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, workload BIGINT, category TEXT DEFAULT \\'\\'::TEXT NOT NULL);\\nCREATE TABLE public.program_requirement (program_id BIGINT NOT NULL, category TEXT NOT NULL, min_credit BIGINT, additional_req TEXT);\\nCREATE TABLE public.semester (semester_id BIGINT NOT NULL, semester TEXT, year BIGINT);\\nCREATE TABLE public.student (student_id BIGINT NOT NULL, lastname TEXT, firstname TEXT, program_id BIGINT, declare_major TEXT, total_credit BIGINT, total_gpa NUMERIC, entered_as TEXT DEFAULT \\'firstyear\\'::TEXT, admit_term DATE, predicted_graduation_semester DATE, degree TEXT, minor TEXT, internship TEXT);\\nCREATE TABLE public.student_record (student_id BIGINT NOT NULL, course_id BIGINT NOT NULL, semester BIGINT NOT NULL, grade TEXT, how TEXT, transfer_source TEXT, earn_credit TEXT DEFAULT \\'y\\'::TEXT NOT NULL, repeat_term TEXT, test_id TEXT, offering_id BIGINT);\\n\\n### Answer\\nGiven the database schema, here is the SQL query that answers [QUESTION]What is the total number of credits earned by students in each program?[/QUESTION]\\n[SQL]SELECT program.name, program.program_id, SUM(student.total_credit) AS total_credits FROM student JOIN program ON student.program_id = program.program_id GROUP BY program.name, program.program_id;[/SQL]'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e50fa3d2a4444ead4e0119c359a20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train = prepare_dataset_for_training(split_dataset[\"train\"], prompt_file=\"./prompts/prompt_v4_train.md\")\n",
    "split_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Task\\nGenerate a SQL query to answer [QUESTION]Which type of policy is most frequently used? Give me the policy type code.[/QUESTION]\\n\\n### Instructions\\n- End the SQL query with \";\"\\n- Do not explain the Answer SQL\\n\\n### Database Schema\\nThe query will run on a database with the following schema:\\nCREATE TABLE policies (policy_type_code VARCHAR)\\n\\n### Answer\\nGiven the database schema, here is the SQL query that answers [QUESTION]Which type of policy is most frequently used? Give me the policy type code.[/QUESTION]\\n[SQL]SELECT policy_type_code FROM policies GROUP BY policy_type_code ORDER BY COUNT(*) DESC LIMIT 1;[/SQL]'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"train\"] = concatenate_datasets([split_train] + [eval_train]*10).shuffle(seed=42)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    eval_train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    eval_test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"eval_train\"] = eval_train_test[\"train\"]\n",
    "split_dataset[\"eval_test\"] = eval_train_test[\"test\"]\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db1ec7b57674bcdb17f0fb28490c744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccbe602736f4292bd9b0c4784c27551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8cb11e18f6448dbbee7c1aec598455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbb6d8510ce4fc8af9cea1cd184bbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302e6501c88244aebb53478e7bc7d6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = \"./datasets/train_merge_150x10_1500_diff_prompt_gold\"\n",
    "split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Task\\nGenerate a SQL query to answer [QUESTION]What is the ratio of papers that have more than 1 keyphrases to papers that have 1 keyphrase?[/QUESTION]\\n\\n### Instructions\\n- Use PostgreSQL Syntax\\n- End the SQL query with \";\"\\n\\n### Database Schema\\nThe query will run on a database with the following schema:\\nCREATE TABLE public.author (authorid bigint NOT NULL, authorname text);\\n\\nCREATE TABLE public.cite (citingpaperid bigint NOT NULL, citedpaperid bigint NOT NULL);\\n\\nCREATE TABLE public.dataset (datasetid bigint NOT NULL, datasetname text);\\n\\nCREATE TABLE public.field (fieldid bigint);\\n\\nCREATE TABLE public.journal (journalid bigint NOT NULL, journalname text);\\n\\nCREATE TABLE public.keyphrase (keyphraseid bigint NOT NULL, keyphrasename text);\\n\\nCREATE TABLE public.paper (paperid bigint NOT NULL, title text, venueid bigint, year bigint, numciting bigint, numcitedby bigint, journalid bigint);\\n\\nCREATE TABLE public.paperdataset (paperid bigint, datasetid bigint);\\n\\nCREATE TABLE public.paperfield (fieldid bigint, paperid bigint);\\n\\nCREATE TABLE public.paperkeyphrase (paperid bigint, keyphraseid bigint);\\n\\nCREATE TABLE public.venue (venueid bigint NOT NULL, venuename text);\\n\\nCREATE TABLE public.writes (paperid bigint, authorid bigint);\\n\\n### Answer\\nGiven the database schema, here is the SQL query that answers [QUESTION]What is the ratio of papers that have more than 1 keyphrases to papers that have 1 keyphrase?[/QUESTION]\\n[SQL]SELECT CAST(COUNT(DISTINCT CASE WHEN keyphrase_count > 1 THEN subquery.paperid END) AS FLOAT) / NULLIF(COUNT(DISTINCT CASE WHEN keyphrase_count =1 THEN subquery.paperid END), 0) AS ratio FROM (SELECT paperkeyphrase.paperid, COUNT(paperkeyphrase.keyphraseid) AS keyphrase_count FROM paperkeyphrase GROUP BY paperkeyphrase.paperid) AS subquery;[/SQL]'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"train\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
