{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, load_from_disk, concatenate_datasets, disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder where the dataset was saved\n",
    "cache_dir = \"./datasets\"\n",
    "\n",
    "# Load the dataset from the saved folder\n",
    "dataset = load_dataset(\"b-mc2/sql-create-context\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 78577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT COUNT(*) FROM head WHERE age > 56',\n",
       " 'question': 'How many heads of the departments are older than 56 ?',\n",
       " 'context': 'CREATE TABLE head (age INTEGER)'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset['train'].take(2000)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testval_split = train_data.train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "# Further split the test+val set into validation and test (e.g., 50% of 20% = 10% each)\n",
    "test_val_split = train_testval_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Combine splits into a DatasetDict\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_testval_split[\"train\"],\n",
    "    \"val\": test_val_split[\"train\"],\n",
    "    \"test\": test_val_split[\"test\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./datasets/sql-create-context-split\"\n",
    "# split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset = load_from_disk(\"./datasets/sql-create-context-split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    eval: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = load_dataset(\"json\", data_files={'eval':\"./datasets/sql_eval_dataset.json\"})\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train_test = eval_dataset[\"eval\"].train_test_split(test_size=0.4, seed=42)\n",
    "eval_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    train_append: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train_test[\"train_append\"] = eval_train_test[\"train\"].select_columns(['answer', 'question', 'context'])\n",
    "eval_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1950\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"train\"] = concatenate_datasets([split_dataset[\"train\"]] + [eval_train_test[\"train_append\"]]*3)\n",
    "split_dataset[\"train\"] = split_dataset[\"train\"].shuffle(seed=42)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1950\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    eval_train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    eval_test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"eval_train\"] = eval_train_test[\"train\"]\n",
    "split_dataset[\"eval_test\"] = eval_train_test[\"test\"]\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./datasets/sql-create-context-split\"\n",
    "# split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT CAST(COUNT(DISTINCT CASE WHEN keyphrase_count > 1 THEN subquery.paperid END) AS FLOAT) / NULLIF(COUNT(DISTINCT CASE WHEN keyphrase_count =1 THEN subquery.paperid END), 0) AS ratio FROM (SELECT paperkeyphrase.paperid, COUNT(paperkeyphrase.keyphraseid) AS keyphrase_count FROM paperkeyphrase GROUP BY paperkeyphrase.paperid) AS subquery;',\n",
       " 'question': 'What is the ratio of papers that have more than 1 keyphrases to papers that have 1 keyphrase?',\n",
       " 'context': 'CREATE TABLE public.author (authorid bigint NOT NULL, authorname text);\\n\\nCREATE TABLE public.cite (citingpaperid bigint NOT NULL, citedpaperid bigint NOT NULL);\\n\\nCREATE TABLE public.dataset (datasetid bigint NOT NULL, datasetname text);\\n\\nCREATE TABLE public.field (fieldid bigint);\\n\\nCREATE TABLE public.journal (journalid bigint NOT NULL, journalname text);\\n\\nCREATE TABLE public.keyphrase (keyphraseid bigint NOT NULL, keyphrasename text);\\n\\nCREATE TABLE public.paper (paperid bigint NOT NULL, title text, venueid bigint, year bigint, numciting bigint, numcitedby bigint, journalid bigint);\\n\\nCREATE TABLE public.paperdataset (paperid bigint, datasetid bigint);\\n\\nCREATE TABLE public.paperfield (fieldid bigint, paperid bigint);\\n\\nCREATE TABLE public.paperkeyphrase (paperid bigint, keyphraseid bigint);\\n\\nCREATE TABLE public.venue (venueid bigint NOT NULL, venuename text);\\n\\nCREATE TABLE public.writes (paperid bigint, authorid bigint);'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"train\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
