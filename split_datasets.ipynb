{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, load_from_disk, concatenate_datasets, disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder where the dataset was saved\n",
    "cache_dir = \"./datasets\"\n",
    "\n",
    "# Load the dataset from the saved folder\n",
    "dataset = load_dataset(\"b-mc2/sql-create-context\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 78577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT COUNT(*) FROM head WHERE age > 56',\n",
       " 'question': 'How many heads of the departments are older than 56 ?',\n",
       " 'context': 'CREATE TABLE head (age INTEGER)'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset['train'].take(2000)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testval_split = train_data.train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "# Further split the test+val set into validation and test (e.g., 50% of 20% = 10% each)\n",
    "test_val_split = train_testval_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Combine splits into a DatasetDict\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_testval_split[\"train\"],\n",
    "    \"val\": test_val_split[\"train\"],\n",
    "    \"test\": test_val_split[\"test\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./datasets/sql-create-context-split\"\n",
    "# split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset = load_from_disk(\"./datasets/sql-create-context-split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    eval: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = load_dataset(\"json\", data_files={'eval':\"./datasets/sql_eval_dataset.json\"})\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train_test = eval_dataset[\"eval\"].train_test_split(test_size=0.4, seed=42)\n",
    "eval_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    train_append: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train_test[\"train_append\"] = eval_train_test[\"train\"].select_columns(['answer', 'question', 'context'])\n",
    "eval_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_for_training(dataset, prompt_file):\n",
    "    with open(prompt_file, \"r\") as f:\n",
    "        prompt = f.read()\n",
    "    columns = dataset.features.keys()\n",
    "\n",
    "    def preprocess_function(sample):\n",
    "        sample[\"text\"] = prompt.format(\n",
    "            user_question=sample[\"question\"],\n",
    "            table_metadata_string=sample[\"context\"],\n",
    "            sql=(\n",
    "                sample[\"answer\"]\n",
    "                if sample[\"answer\"].endswith(\";\")\n",
    "                else sample[\"answer\"] + \";\"\n",
    "            ),\n",
    "        ).strip()\n",
    "\n",
    "        return sample\n",
    "\n",
    "    train_dataset = dataset.map(\n",
    "        preprocess_function,\n",
    "        remove_columns=columns,\n",
    "    )\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb41ead2f5a4ba59e5b1dbc69d9389f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 150\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train = prepare_dataset_for_training(eval_train_test[\"train_append\"], prompt_file=\"./prompts/prompt_v4_postgres_train.md\")\n",
    "eval_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Task\\nGenerate a SQL query to answer [QUESTION]What is the total number of credits earned by students in each program?[/QUESTION]\\n\\n### Instructions\\n- Use PostgreSQL Syntax\\n- End the SQL query with \";\"\\n\\n### Database Schema\\nThe query will run on a database with the following schema:\\nCREATE TABLE public.area (course_id BIGINT, area TEXT);\\nCREATE TABLE public.comment_instructor (instructor_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, student_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, score BIGINT, comment_text TEXT);\\nCREATE TABLE public.course (course_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, name TEXT, department TEXT, number TEXT, credits TEXT, advisory_requirement TEXT, enforced_requirement TEXT, description TEXT, num_semesters BIGINT, num_enrolled BIGINT, has_discussion BOOLEAN, has_lab BOOLEAN, has_projects BOOLEAN, has_exams BOOLEAN, num_reviews BIGINT, clarity_score BIGINT, easiness_score BIGINT, helpfulness_score BIGINT);\\nCREATE TABLE public.course_offering (offering_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, course_id BIGINT, semester BIGINT, section_number BIGINT, start_time TIME, end_time TIME, monday TEXT, tuesday TEXT, wednesday TEXT, thursday TEXT, friday TEXT, saturday TEXT, sunday TEXT, has_final_project BOOLEAN, has_final_exam BOOLEAN, textbook TEXT, class_address TEXT, allow_audit TEXT DEFAULT \\'false\\'::TEXT);\\nCREATE TABLE public.course_prerequisite (pre_course_id BIGINT NOT NULL, course_id BIGINT NOT NULL);\\nCREATE TABLE public.course_tags_count (course_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, clear_grading BIGINT DEFAULT \\'0\\'::BIGINT, pop_quiz BIGINT DEFAULT \\'0\\'::BIGINT, group_projects BIGINT DEFAULT \\'0\\'::BIGINT, inspirational BIGINT DEFAULT \\'0\\'::BIGINT, long_lectures BIGINT DEFAULT \\'0\\'::BIGINT, extra_credit BIGINT DEFAULT \\'0\\'::BIGINT, few_tests BIGINT DEFAULT \\'0\\'::BIGINT, good_feedback BIGINT DEFAULT \\'0\\'::BIGINT, tough_tests BIGINT DEFAULT \\'0\\'::BIGINT, heavy_papers BIGINT DEFAULT \\'0\\'::BIGINT, cares_for_students BIGINT DEFAULT \\'0\\'::BIGINT, heavy_assignments BIGINT DEFAULT \\'0\\'::BIGINT, respected BIGINT DEFAULT \\'0\\'::BIGINT, participation BIGINT DEFAULT \\'0\\'::BIGINT, heavy_reading BIGINT DEFAULT \\'0\\'::BIGINT, tough_grader BIGINT DEFAULT \\'0\\'::BIGINT, hilarious BIGINT DEFAULT \\'0\\'::BIGINT, would_take_again BIGINT DEFAULT \\'0\\'::BIGINT, good_lecture BIGINT DEFAULT \\'0\\'::BIGINT, no_skip BIGINT DEFAULT \\'0\\'::BIGINT);\\nCREATE TABLE public.instructor (instructor_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, name TEXT, uniqname TEXT);\\nCREATE TABLE public.offering_instructor (offering_instructor_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, offering_id BIGINT, instructor_id BIGINT);\\nCREATE TABLE public.program (program_id BIGINT NOT NULL, name TEXT, college TEXT, introduction TEXT);\\nCREATE TABLE public.program_course (program_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, course_id BIGINT DEFAULT \\'0\\'::BIGINT NOT NULL, workload BIGINT, category TEXT DEFAULT \\'\\'::TEXT NOT NULL);\\nCREATE TABLE public.program_requirement (program_id BIGINT NOT NULL, category TEXT NOT NULL, min_credit BIGINT, additional_req TEXT);\\nCREATE TABLE public.semester (semester_id BIGINT NOT NULL, semester TEXT, year BIGINT);\\nCREATE TABLE public.student (student_id BIGINT NOT NULL, lastname TEXT, firstname TEXT, program_id BIGINT, declare_major TEXT, total_credit BIGINT, total_gpa NUMERIC, entered_as TEXT DEFAULT \\'firstyear\\'::TEXT, admit_term DATE, predicted_graduation_semester DATE, degree TEXT, minor TEXT, internship TEXT);\\nCREATE TABLE public.student_record (student_id BIGINT NOT NULL, course_id BIGINT NOT NULL, semester BIGINT NOT NULL, grade TEXT, how TEXT, transfer_source TEXT, earn_credit TEXT DEFAULT \\'y\\'::TEXT NOT NULL, repeat_term TEXT, test_id TEXT, offering_id BIGINT);\\n\\n### Answer\\nGiven the database schema, here is the SQL query that answers [QUESTION]What is the total number of credits earned by students in each program?[/QUESTION]\\n[SQL]SELECT {program.name, program.program_id}, SUM(student.total_credit) AS total_credits FROM student JOIN program ON student.program_id = program.program_id GROUP BY {};[/SQL]'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc848176b39f4c039a47b0c4cb83f7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 750\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train = prepare_dataset_for_training(split_dataset[\"train\"].take(750), prompt_file=\"./prompts/prompt_v4_train.md\")\n",
    "split_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Task\\nGenerate a SQL query to answer [QUESTION]Which type of policy is most frequently used? Give me the policy type code.[/QUESTION]\\n\\n### Instructions\\n- End the SQL query with \";\"\\n- Do not explain the Answer SQL\\n\\n### Database Schema\\nThe query will run on a database with the following schema:\\nCREATE TABLE policies (policy_type_code VARCHAR)\\n\\n### Answer\\nGiven the database schema, here is the SQL query that answers [QUESTION]Which type of policy is most frequently used? Give me the policy type code.[/QUESTION]\\n[SQL]SELECT policy_type_code FROM policies GROUP BY policy_type_code ORDER BY COUNT(*) DESC LIMIT 1;[/SQL]'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"train\"] = concatenate_datasets([split_train] + [eval_train]*5).shuffle(seed=42)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    eval_train: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "    eval_test: Dataset({\n",
       "        features: ['question', 'answer', 'db_name', 'context', 'query_category'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"eval_train\"] = eval_train_test[\"train\"]\n",
    "split_dataset[\"eval_test\"] = eval_train_test[\"test\"]\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./datasets/train_merge_150x5_750_diff_prompt\"\n",
    "# split_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Task\\nGenerate a SQL query to answer [QUESTION]Which restaurants serve Italian cuisine or are located in New York? Order the results by the restaurant name.[/QUESTION]\\n\\n### Instructions\\n- Use PostgreSQL Syntax\\n- End the SQL query with \";\"\\n\\n### Database Schema\\nThe query will run on a database with the following schema:\\nCREATE TABLE public.geographic (city_name text, county text, region text);\\n\\nCREATE TABLE public.location (restaurant_id bigint, house_number bigint, street_name text, city_name text);\\n\\nCREATE TABLE public.restaurant (id bigint, name text, food_type text, city_name text, rating real);\\n\\n### Answer\\nGiven the database schema, here is the SQL query that answers [QUESTION]Which restaurants serve Italian cuisine or are located in New York? Order the results by the restaurant name.[/QUESTION]\\n[SQL]SELECT name FROM restaurant WHERE food_type ILIKE \\'%Italian%\\' OR city_name ILIKE \\'%New York%\\' ORDER BY name NULLS LAST;[/SQL]'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset[\"train\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
